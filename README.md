Trees by Hand â€“ Classification with Decision Tree (Midterm Project)
This notebook is part of the OPIM 5512: Data Science Using Python course at the University of Connecticut. The project demonstrates how to manually construct a classification decision tree using a simplified version of the California Housing dataset.

ğŸ“˜ Project Overview
The goal of this assignment is to manually calculate the first-level split of a decision tree classifier using entropy as the splitting criterion. Each student uses a unique random seed (student ID) to generate personalized data distributions.

The dataset includes selected columns from the California Housing dataset:

housing_median_age

total_rooms

median_income

median_house_value

The target variable is already binarized, converting this into a binary classification problem.

ğŸ”§ Key Concepts
Decision Tree Classifier with depth = 1

Entropy-based Information Gain calculations

Manual computation of tree splits to reinforce understanding of classification algorithms

Data preparation and recoding to fit a classification framework

ğŸ› ï¸ Technologies Used
Python

Pandas & NumPy

Jupyter Notebook

ğŸ“‚ Instructions
Change the theSeed variable to your own 7-digit student ID.

Follow the guided steps to compute class distributions, entropies, and information gains.

Replicate the results by hand (submit handwritten calculations as a PDF).

Compare manual computations with model results for validation.

ğŸ”— Connect With Me
If you're hiring for financial analytics, data science, or quant rolesâ€”
Luis PazmiÃ±o | [LinkedIn](https://www.linkedin.com/in/luis-pazmino-702838248/) | Based in NYC
Iâ€™m open to challenging opportunities in finance, risk modeling, and business strategy powered by data.
